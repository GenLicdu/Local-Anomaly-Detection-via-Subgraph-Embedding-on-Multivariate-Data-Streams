{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scale(pd.read_csv('Dynamicgraph_ACCESS7.csv').iloc[:,1:-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 16)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    for j in range(df.shape[1]):\n",
    "        if df[i][j] == 0:\n",
    "            df[i][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.abs(df.reshape(df.shape[0],4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    # 替换NaN值为均值\n",
    "    nan_mask = np.isnan(data)\n",
    "    data[nan_mask] = np.nanmean(data)\n",
    "    \n",
    "    # 或者替换为特定的值，例如 0\n",
    "    # data[nan_mask] = 0  # 替换为0\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.01805094, 0.56593093, 0.28111563],\n",
       "       [0.01805094, 1.        , 0.29698762, 0.24295839],\n",
       "       [0.56593093, 0.29698762, 1.        , 0.27893633],\n",
       "       [0.28111563, 0.24295839, 0.27893633, 1.        ]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(X):\n",
    "    E = []\n",
    "    for i in range(X.shape[0]):\n",
    "        P = []\n",
    "        for j in range(X.shape[1]):\n",
    "            if i !=j:\n",
    "                e = -X[i][j]*np.log(X[i][j])\n",
    "                P.append(e)\n",
    "        P = np.array(P)\n",
    "        E.append(np.sum(P))\n",
    "    return np.array(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphentropy(X):\n",
    "    E = []\n",
    "    for i in range(X.shape[0]):\n",
    "        e = entropy(X[i])\n",
    "        E.append(np.sum(e))\n",
    "    return np.array(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies = graphentropy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inf in entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = cdist(entropies.reshape(-1, 1), entropies.reshape(-1, 1), metric='euclidean')\n",
    "distances.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_indices = np.argmin(distances, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=16):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "# Transformer Encoder\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, ff_dim, num_layers):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        return x\n",
    "\n",
    "# Autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, bottleneck_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, bottleneck_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(bottleneck_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 16\n",
    "embed_dim = 16\n",
    "num_heads = 4\n",
    "ff_dim = 128\n",
    "num_layers = 3\n",
    "hidden_dim = 32\n",
    "bottleneck_dim = 16\n",
    "lr = 0.01\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_encoder = TransformerEncoder(input_dim, embed_dim, num_heads, ff_dim, num_layers)\n",
    "autoencoder = Autoencoder(input_dim, hidden_dim, bottleneck_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(list(transformer_encoder.parameters()) + list(autoencoder.parameters()), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.78036223, 0.98857452, 0.84882841],\n",
       "       [0.78036223, 1.        , 1.16690413, 0.42749557],\n",
       "       [0.98857452, 1.16690413, 1.        , 1.14361819],\n",
       "       [0.84882841, 0.42749557, 1.14361819, 1.        ]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 9.9087e-01, 5.0363e-01, 2.8071e-01, 9.9087e-01, 1.0000e+00,\n",
       "         1.2818e+00, 1.2847e+00, 5.0363e-01, 1.2818e+00, 1.0000e+00, 5.3874e-01,\n",
       "         2.8071e-01, 1.2847e+00, 5.3874e-01, 2.2204e-16]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(data[2].flatten(), dtype=torch.float32).unsqueeze(0)\n",
    "similar_x = torch.tensor(data[most_similar_indices[2]].flatten(), dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "similar_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.00000000e+00, 9.90870323e-01, 5.03633203e-01, 2.80707435e-01],\n",
       "        [9.90870323e-01, 1.00000000e+00, 1.28182437e+00, 1.28466234e+00],\n",
       "        [5.03633203e-01, 1.28182437e+00, 1.00000000e+00, 5.38744045e-01],\n",
       "        [2.80707435e-01, 1.28466234e+00, 5.38744045e-01, 2.22044605e-16]]),\n",
       " array([[1.        , 0.01805094, 0.56593093, 0.28111563],\n",
       "        [0.01805094, 1.        , 0.29698762, 0.24295839],\n",
       "        [0.56593093, 0.29698762, 1.        , 0.27893633],\n",
       "        [0.28111563, 0.24295839, 0.27893633, 1.        ]]),\n",
       " 2)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[most_similar_indices[2]],data[5],most_similar_indices[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 16])) that is different to the input size (torch.Size([1, 1, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.3545854719541967\n",
      "Epoch 2/50, Loss: 0.27047521630302074\n",
      "Epoch 3/50, Loss: 0.24667332739569248\n",
      "Epoch 4/50, Loss: 0.240764530133456\n",
      "Epoch 5/50, Loss: 0.23957975958473982\n",
      "Epoch 6/50, Loss: 0.23454898681491612\n",
      "Epoch 7/50, Loss: 0.2352264958806336\n",
      "Epoch 8/50, Loss: 0.23373521105386316\n",
      "Epoch 9/50, Loss: 0.23426728431135416\n",
      "Epoch 10/50, Loss: 0.23373165619559585\n",
      "Epoch 11/50, Loss: 0.23311674419790507\n",
      "Epoch 12/50, Loss: 0.23301371506415308\n",
      "Epoch 13/50, Loss: 0.23244138691574334\n",
      "Epoch 14/50, Loss: 0.23129835310392083\n",
      "Epoch 15/50, Loss: 0.23002781852148474\n",
      "Epoch 16/50, Loss: 0.2294008821155876\n",
      "Epoch 17/50, Loss: 0.23002006785012782\n",
      "Epoch 18/50, Loss: 0.22870499855838716\n",
      "Epoch 19/50, Loss: 0.2315006744582206\n",
      "Epoch 20/50, Loss: 0.2294099312182516\n",
      "Epoch 21/50, Loss: 0.2304657519236207\n",
      "Epoch 22/50, Loss: 0.2294485124014318\n",
      "Epoch 23/50, Loss: 0.22889952807687222\n",
      "Epoch 24/50, Loss: 0.23051330741494894\n",
      "Epoch 25/50, Loss: 0.23016918311826884\n",
      "Epoch 26/50, Loss: 0.2323167350050062\n",
      "Epoch 27/50, Loss: 0.22994369197636844\n",
      "Epoch 28/50, Loss: 0.2296347767021507\n",
      "Epoch 29/50, Loss: 0.2294632109394297\n",
      "Epoch 30/50, Loss: 0.23294053614605217\n",
      "Epoch 31/50, Loss: 0.23051111354492604\n",
      "Epoch 32/50, Loss: 0.2302353542437777\n",
      "Epoch 33/50, Loss: 0.23418172006495297\n",
      "Epoch 34/50, Loss: 0.22865955892018974\n",
      "Epoch 35/50, Loss: 0.23018540808930993\n",
      "Epoch 36/50, Loss: 0.22959394035860897\n",
      "Epoch 37/50, Loss: 0.22951963029801845\n",
      "Epoch 38/50, Loss: 0.23190098899416625\n",
      "Epoch 39/50, Loss: 0.23106092941947282\n",
      "Epoch 40/50, Loss: 0.23039686840958892\n",
      "Epoch 41/50, Loss: 0.22954395736567676\n",
      "Epoch 42/50, Loss: 0.229959614938125\n",
      "Epoch 43/50, Loss: 0.22944635921157897\n",
      "Epoch 44/50, Loss: 0.22948975200764835\n",
      "Epoch 45/50, Loss: 0.2275794326327741\n",
      "Epoch 46/50, Loss: 0.22908683887682854\n",
      "Epoch 47/50, Loss: 0.22929540202952922\n",
      "Epoch 48/50, Loss: 0.23434805685654284\n",
      "Epoch 49/50, Loss: 0.23047014126554133\n",
      "Epoch 50/50, Loss: 0.22864839277230203\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for i in range(len(data)):\n",
    "        x = torch.tensor(data[i].flatten(), dtype=torch.float32).unsqueeze(0)\n",
    "        similar_x = torch.tensor(data[most_similar_indices[i]].flatten(), dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        transformer_output = transformer_encoder(x)\n",
    "\n",
    "        # Autoencoder\n",
    "        encoded, decoded = autoencoder(similar_x)\n",
    "\n",
    "        # 损失计算\n",
    "        loss1 = mse_loss(transformer_output, encoded)\n",
    "        loss2 = mse_loss(similar_x, decoded)\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(data)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, data):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(data)):\n",
    "            x = torch.tensor(data[i].flatten(), dtype=torch.float32).unsqueeze(0)\n",
    "            embedding = model(x)\n",
    "            embeddings.append(embedding.squeeze(0).numpy())\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# 获取嵌入向量\n",
    "embeddings = get_embeddings(transformer_encoder, data)\n",
    "#np.savetxt('Embedding_vector.csv', embeddings, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "np.save('Embeddings_ACCESS7_ETA.npy', embeddings)\n",
    "\n",
    "print(\"Embeddings saved to embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
